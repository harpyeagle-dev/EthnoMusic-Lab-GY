<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Recording Test - Diagnostics</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 40px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .test-section {
            background: white;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
        }
        .btn-primary {
            background: #667eea;
            color: white;
        }
        .btn-secondary {
            background: #6c757d;
            color: white;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
        }
        .success { background: #d4edda; color: #155724; }
        .error { background: #f8d7da; color: #721c24; }
        .info { background: #d1ecf1; color: #0c5460; }
        pre {
            background: #f8f9fa;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
            font-size: 12px;
        }
    </style>
</head>
<body>
    <h1>üîß Recording Feature Diagnostics</h1>
    
    <div class="test-section">
        <h2>Test 1: Microphone Access</h2>
        <button class="btn-primary" onclick="testMicrophone()">Test Microphone</button>
        <div id="mic-status"></div>
    </div>

    <div class="test-section">
        <h2>Test 2: Recording & Playback</h2>
        <button class="btn-primary" onclick="startRecording()">Start Recording</button>
        <button class="btn-secondary" onclick="stopRecording()" disabled id="stop-btn">Stop Recording</button>
        <div id="recording-status"></div>
        <div id="playback-area" style="margin-top: 20px;"></div>
    </div>

    <div class="test-section">
        <h2>Test 3: Audio Analysis</h2>
        <button class="btn-primary" onclick="testAnalysis()" id="analyze-btn" disabled>Analyze Recording</button>
        <div id="analysis-status"></div>
    </div>

    <div class="test-section">
        <h2>Console Logs</h2>
        <button class="btn-secondary" onclick="clearLogs()">Clear Logs</button>
        <pre id="console-logs"></pre>
    </div>

    <script>
        let mediaRecorder = null;
        let audioChunks = [];
        let audioBlob = null;
        let audioContext = null;

        function log(message, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const logDiv = document.getElementById('console-logs');
            const color = type === 'error' ? 'red' : type === 'success' ? 'green' : 'blue';
            logDiv.innerHTML += `<div style="color: ${color}">[${timestamp}] ${message}</div>`;
            logDiv.scrollTop = logDiv.scrollHeight;
            console.log(message);
        }

        function clearLogs() {
            document.getElementById('console-logs').innerHTML = '';
        }

        async function testMicrophone() {
            const statusDiv = document.getElementById('mic-status');
            try {
                log('Testing microphone access...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                statusDiv.innerHTML = '<div class="status success">‚úÖ Microphone access granted!</div>';
                log('‚úÖ Microphone access successful', 'success');
                stream.getTracks().forEach(track => track.stop());
            } catch (error) {
                statusDiv.innerHTML = `<div class="status error">‚ùå Error: ${error.message}</div>`;
                log(`‚ùå Microphone error: ${error.message}`, 'error');
            }
        }

        async function startRecording() {
            const statusDiv = document.getElementById('recording-status');
            try {
                log('Starting recording...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.addEventListener('dataavailable', event => {
                    audioChunks.push(event.data);
                    log(`Audio chunk received: ${event.data.size} bytes`);
                });
                
                mediaRecorder.addEventListener('stop', () => {
                    log('Recording stopped');
                    audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    log(`Audio blob created: ${audioBlob.size} bytes`, 'success');
                    
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const playbackArea = document.getElementById('playback-area');
                    playbackArea.innerHTML = `
                        <h3>Recorded Audio:</h3>
                        <audio controls src="${audioUrl}" style="width: 100%;"></audio>
                        <p>Size: ${(audioBlob.size / 1024).toFixed(2)} KB</p>
                    `;
                    
                    document.getElementById('analyze-btn').disabled = false;
                    stream.getTracks().forEach(track => track.stop());
                });
                
                mediaRecorder.start();
                document.getElementById('stop-btn').disabled = false;
                document.querySelector('[onclick="startRecording()"]').disabled = true;
                statusDiv.innerHTML = '<div class="status info">üî¥ Recording in progress...</div>';
                log('üî¥ Recording started', 'success');
            } catch (error) {
                statusDiv.innerHTML = `<div class="status error">‚ùå Error: ${error.message}</div>`;
                log(`‚ùå Recording error: ${error.message}`, 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                document.getElementById('stop-btn').disabled = true;
                document.querySelector('[onclick="startRecording()"]').disabled = false;
                document.getElementById('recording-status').innerHTML = '<div class="status success">‚úÖ Recording complete!</div>';
                log('‚úÖ Recording stopped successfully', 'success');
            }
        }

        async function testAnalysis() {
            const statusDiv = document.getElementById('analysis-status');
            if (!audioBlob) {
                statusDiv.innerHTML = '<div class="status error">‚ùå No recording to analyze</div>';
                return;
            }

            try {
                log('Starting audio analysis...');
                statusDiv.innerHTML = '<div class="status info">üîÑ Analyzing audio...</div>';
                
                // Initialize audio context
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    log(`AudioContext created: Sample rate ${audioContext.sampleRate} Hz`);
                }
                
                // Convert to ArrayBuffer
                log('Converting blob to ArrayBuffer...');
                const arrayBuffer = await audioBlob.arrayBuffer();
                log(`ArrayBuffer created: ${arrayBuffer.byteLength} bytes`);
                
                // Decode audio
                log('Decoding audio data...');
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer.slice(0));
                log(`‚úÖ Audio decoded: Duration ${audioBuffer.duration.toFixed(2)}s, Channels: ${audioBuffer.numberOfChannels}`, 'success');
                
                // Get channel data
                const channelData = audioBuffer.getChannelData(0);
                log(`Channel data: ${channelData.length} samples`);
                
                // Simple analysis
                let sum = 0;
                let max = 0;
                for (let i = 0; i < channelData.length; i++) {
                    const abs = Math.abs(channelData[i]);
                    sum += abs;
                    if (abs > max) max = abs;
                }
                const average = sum / channelData.length;
                
                statusDiv.innerHTML = `
                    <div class="status success">
                        <h4>‚úÖ Analysis Complete!</h4>
                        <p><strong>Duration:</strong> ${audioBuffer.duration.toFixed(2)} seconds</p>
                        <p><strong>Sample Rate:</strong> ${audioBuffer.sampleRate} Hz</p>
                        <p><strong>Samples:</strong> ${channelData.length}</p>
                        <p><strong>Average Amplitude:</strong> ${(average * 100).toFixed(2)}%</p>
                        <p><strong>Peak Amplitude:</strong> ${(max * 100).toFixed(2)}%</p>
                    </div>
                `;
                log('‚úÖ Analysis complete!', 'success');
                
            } catch (error) {
                statusDiv.innerHTML = `<div class="status error">‚ùå Analysis Error: ${error.message}</div>`;
                log(`‚ùå Analysis error: ${error.message}`, 'error');
                console.error(error);
            }
        }

        // Log initial browser info
        log(`Browser: ${navigator.userAgent}`);
        log(`MediaRecorder supported: ${!!window.MediaRecorder}`);
        log(`AudioContext supported: ${!!(window.AudioContext || window.webkitAudioContext)}`);
    </script>
</body>
</html>
